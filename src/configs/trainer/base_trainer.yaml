trainer:
  num_nodes: int = 1

    #
    # logger: Union[pytorch_lightning.loggers.base.LightningLoggerBase, Iterable[pytorch_lightning.loggers.base.LightningLoggerBase], bool] = True,
    # checkpoint_callback: Union[pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint, bool] = True,
    # early_stop_callback: Union[pytorch_lightning.callbacks.early_stopping.EarlyStopping, bool, NoneType] = False,
    # callbacks: Union[List[pytorch_lightning.callbacks.base.Callback], NoneType] = None,
    # default_root_dir: Union[str, NoneType] = None,
    # gradient_clip_val: float = 0,
    # process_position: int = 0,
    # num_nodes: int = 1,
    # num_processes: int = 1,
    # gpus: Union[int, str, List[int], NoneType] = None,
    # auto_select_gpus: bool = False,
    # tpu_cores: Union[int, str, List[int], NoneType] = None,
    # log_gpu_memory: Union[str, NoneType] = None,
    # progress_bar_refresh_rate: int = 1,
    # overfit_batches: Union[int, float] = 0.0,
    # track_grad_norm: Union[int, float, str] = -1,
    # check_val_every_n_epoch: int = 1,
    # fast_dev_run: bool = False,
    # accumulate_grad_batches: Union[int, Dict[int, int], List[list]] = 1,
    # max_epochs: int = 1000,
    # min_epochs: int = 1,
    # max_steps: Union[int, NoneType] = None,
    # min_steps: Union[int, NoneType] = None,
    # limit_train_batches: Union[int, float] = 1.0,
    # limit_val_batches: Union[int, float] = 1.0,
    # limit_test_batches: Union[int, float] = 1.0,
    # val_check_interval: Union[int, float] = 1.0,
    # log_save_interval: int = 100,
    # row_log_interval: int = 50,
    # distributed_backend: Union[str, NoneType] = None,
    # precision: int = 32,
    # print_nan_grads: bool = False,
    # weights_summary: Union[str, NoneType] = 'top',
    # weights_save_path: Union[str, NoneType] = None,
    # num_sanity_val_steps: int = 2,
    # truncated_bptt_steps: Union[int, NoneType] = None,
    # resume_from_checkpoint: Union[str, NoneType] = None,
    # profiler: Union[pytorch_lightning.profiler.profilers.BaseProfiler, bool, NoneType] = None,
    # benchmark: bool = False,
    # deterministic: bool = False,
    # reload_dataloaders_every_epoch: bool = False,
    # auto_lr_find: Union[bool, str] = False,
    # replace_sampler_ddp: bool = True,
    # terminate_on_nan: bool = False,
    # auto_scale_batch_size: Union[str, bool] = False,
    #
